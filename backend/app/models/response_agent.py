import os
# Garanta que est√° usando a vers√£o correta
from openai import OpenAI  # Requer openai >= 1.0.0
from dotenv import load_dotenv
import json

# üî• Carregar vari√°veis do ambiente
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# üî• Configurar o cliente OpenAI
client = OpenAI(api_key=OPENAI_API_KEY)

def formatar_resultados(dados):
    """
    Formata resultados de consultas SQL para apresenta√ß√£o amig√°vel.
    """
    if not dados or len(dados) == 0:
        return "N√£o encontrei dados para sua consulta."
    
    try:
        if isinstance(dados, str):
            return dados
        
        # Se for uma lista de dicion√°rios (resultados SQL)
        if isinstance(dados, list) and isinstance(dados[0], dict):
            # Extrair cabe√ßalhos
            cabecalhos = list(dados[0].keys())
            
            # Formatar como tabela de texto
            resultado = "| " + " | ".join(cabecalhos) + " |\n"
            resultado += "| " + " | ".join(["---" for _ in cabecalhos]) + " |\n"
            
            for item in dados:
                linha = "| " + " | ".join([str(item.get(col, "")) for col in cabecalhos]) + " |"
                resultado += linha + "\n"
            
            return resultado
        
        # Caso seja outro formato
        return str(dados)
    except Exception as e:
        print(f"‚ùå Erro ao formatar resultados: {e}")
        return str(dados)

def gerar_resposta_final(pergunta, resposta_processada):
    """
    Gera a resposta final formatada e amig√°vel para o usu√°rio.
    Utiliza a resposta do agente de processamento.
    """
    print(f"üìå Gerando resposta final para: {pergunta}")
    
    try:
        # Extrair informa√ß√µes da resposta processada
        status = resposta_processada.get("status", "error")
        mensagem = resposta_processada.get("message", "")
        dados = resposta_processada.get("data", "N√£o h√° dados dispon√≠veis.")
        
        # Formatar os dados para apresenta√ß√£o
        dados_formatados = formatar_resultados(dados) if dados else "N√£o h√° dados dispon√≠veis."
        
        # Preparar contexto para o modelo
        context = {
            "pergunta": pergunta,
            "status": status,
            "mensagem": mensagem,
            "dados": dados_formatados
        }
        
        # Instru√ß√µes para o modelo
        system_prompt = """
        Voc√™ √© um assistente educacional amig√°vel e claro da UNISAL. 
        
        Sua tarefa √© reformular as informa√ß√µes de resposta em uma linguagem natural e amig√°vel.
        
        Regras:
        1. Seja conciso e direto - responda em at√© 5 frases curtas.
        2. Mantenha um tom educacional, profissional mas amig√°vel.
        3. Se tiverem dados tabulares, apresente-os de forma organizada e leg√≠vel.
        4. Se n√£o houver dados ou ocorrer um erro, seja honesto e sugira alternativas.
        5. Apresente sempre a informa√ß√£o no contexto da pergunta original.
        """
        
        # Preparar o prompt do usu√°rio com os dados para contextualiza√ß√£o
        user_prompt = f"""
        Pergunta original: {context['pergunta']}
        
        Resultado da consulta:
        Status: {context['status']}
        Mensagem: {context['mensagem']}
        
        Dados encontrados:
        {context['dados']}
        
        Por favor, reformule isso em uma resposta natural e amig√°vel.
        """
        
        # Chamar o modelo
        resposta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=300
        )
        
        resposta_final = resposta.choices[0].message.content.strip()
        print(f"‚úÖ Resposta final gerada com sucesso!")
        
        return resposta_final
    
    except Exception as e:
        print(f"‚ùå Erro ao gerar resposta final: {e}")
        return "Desculpe, ocorreu um erro ao processar sua solicita√ß√£o. Por favor, tente novamente mais tarde."

def agente_resposta(pergunta, resposta_processada=None):
    """
    Processa a resposta final para o usu√°rio.
    """
    print(f"üìå Agente de resposta acionado para: {pergunta}")
    
    # Se n√£o recebeu resposta processada, gera uma resposta direta
    if resposta_processada is None:
        try:
            resposta = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Voc√™ √© um assistente acad√™mico da UNISAL. Seja conciso e √∫til."},
                    {"role": "user", "content": pergunta}
                ],
                max_tokens=150
            )
            resposta_final = resposta.choices[0].message.content.strip()
            print(f"‚úÖ Resposta direta gerada: {resposta_final}")
            return resposta_final
        except Exception as e:
            print(f"‚ùå Erro ao gerar resposta direta: {e}")
            return "Desculpe, n√£o consegui processar sua solicita√ß√£o no momento."
    
    # Se recebeu resposta processada, formata e melhora
    return gerar_resposta_final(pergunta, resposta_processada)